otelcol.receiver.otlp "receiver" {
  grpc {
    endpoint = "0.0.0.0:4317"
  }
  http {
    endpoint = "0.0.0.0:4318"
  }
  debug_metrics {
    disable_high_cardinality_metrics = true
  }
  output {
    metrics = [otelcol.processor.resourcedetection.resource.input]
    logs    = [otelcol.processor.resourcedetection.resource.input]
    traces  = [otelcol.processor.resourcedetection.resource.input]
  }
}

otelcol.processor.resourcedetection "resource" {
  detectors = ["env", "system"]
  output {
    metrics = [otelcol.processor.transform.add_metric_datapoint_attributes.input]
    logs    = [otelcol.processor.k8sattributes.k8s.input]
    traces  = [otelcol.processor.k8sattributes.k8s.input]
  }
}

otelcol.processor.transform "add_metric_datapoint_attributes" {
  error_mode = "ignore"
  metric_statements {
    context = "datapoint"
    statements = [
      "set(attributes[\"deployment.environment\"], resource.attributes[\"deployment.environment\"])",
      "set(attributes[\"service.version\"], resource.attributes[\"service.version\"])",
    ]
  }
  output {
    metrics = [otelcol.processor.k8sattributes.k8s.input]
  }
}

otelcol.processor.k8sattributes "k8s" {
  extract {
    metadata = [
      "k8s.namespace.name",
      "k8s.pod.name",
      "k8s.deployment.name",
      "k8s.statefulset.name",
      "k8s.daemonset.name",
      "k8s.cronjob.name",
      "k8s.job.name",
      "k8s.node.name",
      "k8s.pod.uid",
      "k8s.pod.start_time",
    ]
  }
  pod_association {
    source {
      from = "connection"
    }
  }
  output {
    metrics = [otelcol.processor.transform.enrich.input]
    logs    = [otelcol.processor.transform.enrich.input]
    traces  = [
      otelcol.processor.transform.enrich.input,
      otelcol.connector.host_info.node.input,
    ]
  }
}

otelcol.connector.host_info "node" {
  host_identifiers = ["k8s.node.name"]
  output {
    metrics = [otelcol.processor.batch.host_info_batch.input]
  }
}

otelcol.processor.batch "host_info_batch" {
  output {
    metrics = [otelcol.exporter.prometheus.host_info_metrics.input]
  }
}

otelcol.exporter.prometheus "host_info_metrics" {
  add_metric_suffixes = false
  forward_to          = [prometheus.relabel.metrics_service.receiver]
}

otelcol.processor.transform "enrich" {
  error_mode = "ignore"
  metric_statements {
    context = "resource"
    statements = [
      "set(attributes[\"k8s.cluster.name\"], \"" + env("CLUSTER_NAME") + "\") where attributes[\"k8s.cluster.name\"] == nil",
      "set(attributes[\"service.instance.id\"], attributes[\"k8s.pod.uid\"]) where attributes[\"service.instance.id\"] == nil",
    ]
  }
  log_statements {
    context = "resource"
    statements = [
      "set(attributes[\"pod\"], attributes[\"k8s.pod.name\"])",
      "set(attributes[\"namespace\"], attributes[\"k8s.namespace.name\"])",
      "set(attributes[\"loki.resource.labels\"], \"cluster, namespace, job, pod\")",
      "set(attributes[\"k8s.cluster.name\"], \"" + env("CLUSTER_NAME") + "\") where attributes[\"k8s.cluster.name\"] == nil",
      "set(attributes[\"service.instance.id\"], attributes[\"k8s.pod.uid\"]) where attributes[\"service.instance.id\"] == nil",
    ]
  }
  trace_statements {
    context = "resource"
    statements = [
      "set(attributes[\"k8s.cluster.name\"], \"" + env("CLUSTER_NAME") + "\") where attributes[\"k8s.cluster.name\"] == nil",
      "set(attributes[\"service.instance.id\"], attributes[\"k8s.pod.uid\"]) where attributes[\"service.instance.id\"] == nil",
    ]
  }
  output {
    metrics = [otelcol.processor.filter.drop_health.input]
    logs    = [otelcol.processor.filter.drop_health.input]
    traces  = [otelcol.processor.filter.drop_health.input]
  }
}

otelcol.processor.filter "drop_health" {
  error_mode = "ignore"
  traces {
    span = [
      "attributes[\"http.route\"] == \"/live\"",
      "attributes[\"http.route\"] == \"/healthy\"",
      "attributes[\"http.route\"] == \"/ready\"",
    ]
  }
  output {
    metrics = [otelcol.processor.batch.batch_processor.input]
    logs    = [otelcol.processor.batch.batch_processor.input]
    traces  = [otelcol.processor.batch.batch_processor.input]
  }
}

otelcol.processor.batch "batch_processor" {
  send_batch_size     = 16384
  send_batch_max_size = 0
  timeout             = "2s"
  output {
    metrics = [otelcol.exporter.prometheus.metrics_converter.input]
    logs    = [otelcol.exporter.loki.logs_converter.input]
    traces  = [otelcol.exporter.otlp.tempo.input]
  }
}

otelcol.exporter.prometheus "metrics_converter" {
  add_metric_suffixes = true
  forward_to          = [prometheus.relabel.metrics_service.receiver]
}

otelcol.exporter.loki "logs_converter" {
  forward_to = [loki.process.pod_logs.receiver]
}
